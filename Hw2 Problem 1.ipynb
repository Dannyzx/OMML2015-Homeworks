{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 : Write a program (please attach a printout) which implements the error function and, if needed, its gradient, produces a plot of the function obtained, evaluate the value of the training error and of the test error, analyse the occurrence of overfitting/underfitting varying the number of neurons N and of the parameters Âµ.\n",
    "\\vspace{5mm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.optimize import basinhopping\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from __future__ import division\n",
    "from scipy.optimize import minimize\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "Generating the dataset : \n",
    "\\vspace{5mm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frank_function = lambda x1,x2 : 0.75*np.exp(((-(9*x1 - 2)**2)/4)\n",
    "                                            - ((9*x2 - 2)**2)/4)+ 0.75*np.exp(((-(9*x1 + 1)**2)/49)\n",
    "                                            - (9*x2 + 1)/10) + 0.5*np.exp(((-(9*x1 - 7)**2)/4) \n",
    "                                            - ((9*x2 - 3)**2)/4) - 0.2*np.exp(((-(9*x1 - 4)**2) - (9*x2 - 7)**2))\n",
    "noise = np.random.random(100)\n",
    "x1 = np.random.random(100) \n",
    "x2 = np.random.random(100)\n",
    "y = frank_function(x1,x2) + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "We will split the dataset in 80% training set and 20% test set only for to 'try' to give more significance in the fact that training error must be lower than the test error and not only a result from a chance because the dataset is small and obviusly biased because we have only one particular division of the dataset, to have really significance result we need to apply some resampling methods like k-fold cross-validation.\n",
    "\\vspace{5mm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = np.array([0.9958353402931972, 0.42873694033293397, 0.19217723679077281, 0.71488612997180501, 0.46383126295458199, 0.66974426930329678, 0.066263559118869719, 0.9480058493985315, 0.8293286102121662, 0.18373413163159513, 0.53388220408344977, 0.50324073738249198, 0.76293008039041421, 0.47594723537549088, 0.31172453928619837, 0.61924547015284037, 0.10050134386745091, 0.22260868754229723, 0.35001463623734963, 0.14627717939709295, 0.12496220086685006, 0.77930601347322903, 0.2103113176292718, 0.24387419293013968, 0.23980391985165261, 0.044104757632617675, 0.24483640371542925, 0.96208003929206942, 0.11654413690220777, 0.63143705587409138, 0.060624912194398695, 0.88528551201238537, 0.66895473507556358, 0.42009504181562651, 0.87836160667763197, 0.98322978377675474, 0.6504574724668154, 0.11173592920727737, 0.80141779681303438, 0.13852022417094023, 0.70831228979926153, 0.46300211406841951, 0.44286814519774853, 0.17816460503737608, 0.70472978047986978, 0.57365570952802869, 0.20460602506944792, 0.73378735785721394, 0.95952905903893937, 0.91444372653530392, 0.13372498902170327, 0.94690255416025471, 0.24680129260237649, 0.30989562230781176, 0.65520402087345087, 0.56734498327988336, 0.48986591808406166, 0.85857360617446621, 0.84417203687668374, 0.79265792667341706, 0.84666666473554852, 0.82166351845466745, 0.64784553968701897, 0.91999327127869979, 0.12343924287994767, 0.13062537386951478, 0.98070842831461258, 0.71972856479671987, 0.20037551706588619, 0.027716634803678142, 0.85100602533015657, 0.42124744217495913, 0.21816056776889992, 0.57183349251745408, 0.22996555257457729, 0.069783068851780095, 0.5196544851659386, 0.05847822492603294, 0.56595413408932282, 0.10374195592804847, 0.90363009104415926, 0.78348967124635716, 0.52877806758043822, 0.52815167044008426, 0.97559835113345006, 0.67329543789784951, 0.68521577188286609, 0.46924807604035157, 0.17886471170296414, 0.68547369826537852, 0.91820133362930689, 0.48044285978367574, 0.32368080175862668, 0.56738241760500896, 0.7507906579182293, 0.37467746496173637, 0.85630638169587481, 0.82542188504330716, 0.87175400731606334, 0.10693823146415216])\n",
    "\n",
    "x2 = np.array([0.94397468321531419, 0.84936195002221571, 0.88835416982021786, 0.3351395850229697, 0.97549891609392081, 0.72119695695406094, 0.4939274745463702, 0.77125797617766345, 0.28647300867990189, 0.16863131914855933, 0.49356323038788341, 0.9303842603683905, 0.66803239253919533, 0.65631681110241225, 0.76688456488126211, 0.44684204168158359, 0.78656157786170477, 0.04884277732237885, 0.90946336297546815, 0.16870364522268033, 0.4720782381382822, 0.30536511395253729, 0.42516254747015925, 0.81855813831250035, 0.32866687571563968, 0.064099594073537824, 0.33481634349639156, 0.26967295168356153, 0.32820910408217296, 0.58576377020266801, 0.1732881845977976, 0.61709324581996383, 0.67242628272498461, 0.071976121467904997, 0.30102022547879903, 0.51716404052821929, 0.97968630044852001, 0.67401484176625925, 0.83357660482705476, 0.75123726979469962, 0.18787607762786196, 0.063587956209455565, 0.86199956692065982, 0.0544364524835379, 0.55055201109482943, 0.10263869125293923, 0.83044082378354178, 0.5566460107745711, 0.91251242194400695, 0.16197873782878291, 0.95600518562202197, 0.62717970782907151, 0.39986311307204647, 0.19935892005408506, 0.41744615013056829, 0.81678280998769526, 0.36284615303415446, 0.81155369775834274, 0.72870443999329448, 0.109463804579506, 0.30805212479644006, 0.67124727770600623, 0.92832210910667134, 0.35536125513849426, 0.71085021923839398, 0.1539291640605962, 0.6658898407105236, 0.093397181572599686, 0.11757672792613028, 0.27271543809736731, 0.43347682924975794, 0.94549694393758299, 0.38408573931817336, 0.92164887761276204, 0.37528335331555407, 0.15541746455218863, 0.48392025094558666, 0.077618332074833707, 0.50416754104733674, 0.57862714213252087, 0.55254167878812666, 0.84209257581325403, 0.7283382242577694, 0.39160364535425896, 0.84335603513230295, 0.15035656054203139, 0.76654119847186086, 0.0054528180068394994, 0.64959296700971481, 0.9642020683179986, 0.48356057865888424, 0.054068379178072723, 0.75134942803903526, 0.71549493422473187, 0.20450237412747108, 0.36499776692323715, 0.097649052291734151, 0.38663006018783153, 0.30005284930101594, 0.73733987963229708])\n",
    "\n",
    "y = np.array([0.45093252453337712, 0.58457775874172069, 0.63026554608636864, 1.5052172914161432, 0.59064993591310799, 0.93993252946804384, 1.0129594277143021, 0.74134122205295139, 0.95050119337720695, 1.6388227464507175, 0.95326708773797786, 0.89660815149361106, 0.82887816712389106, 0.94985536703995044, 0.6130267786382253, 0.63150252017494357, 1.1252842539145314, 1.7191076020462788, 0.39614859180529138, 1.2060058055026854, 1.5413824050622584, 0.86083427792378309, 0.90912755527705191, 0.89349387064884689, 1.4229570771519109, 0.98192299554047291, 1.7834377811068904, 0.32141013283495246, 1.9262422748397339, 0.39202672577725967, 1.6961788288109891, 0.86717249998048018, 0.65950822173362245, 0.98676911114030841, 0.65438172141159145, 0.23014744635965495, 0.74340325452276612, 0.92120144611463439, 1.0683218134300163, 0.36382030177645697, 1.3850889564313045, 1.2731834061509817, 0.19397778903653132, 1.004307155601204, 0.75030492422403161, 0.72411469794429273, 0.68424535648401252, 0.5576474122472892, 0.24619007937777626, 1.2404455964218704, 0.51050977413844745, 0.77616727845494027, 0.8710339178097054, 1.5453703019630116, 0.76061981617531882, 0.29050553923937639, 0.53218719596907449, 0.23540720573346213, 1.0369340713126924, 0.93699234061470804, 1.3156524001928374, 0.71428668766986636, 0.76514917619693568, 0.81131133889619722, 0.75784220699370797, 1.5548398499669052, 0.43802687884687008, 0.38580225319744876, 1.1779090120240032, 1.6154832357368245, 0.83870534744007919, 0.6136578568732548, 1.2970612968008293, 0.48569349056618039, 1.8083996267888156, 1.6465286760659117, 1.0668002986775242, 1.5222175682801991, 1.0874307471706597, 1.2436719265473197, 1.1153325666070963, 1.028895686291794, 0.9896633037772522, 0.61531814736196944, 0.51028808330862341, 1.3063665977640542, 0.25866633265684391, 0.74839660516947837, 0.38070761120901331, 0.66192441344541342, 0.7984356133918098, 1.3887457824215181, 0.71021685843743221, 0.43949070039539873, 1.3948088517109727, 0.77491318624600602, 0.8936931991021374, 1.0455502081615169, 1.2115791896556263, 1.0031890864054331])\n",
    "\n",
    "x1_train = x1[0:80]\n",
    "x2_train = x2[0:80]\n",
    "y_train = y[0:80]\n",
    "\n",
    "x1_test = x1[80:100]\n",
    "x2_test = x2[80:100]\n",
    "y_test = y[80:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will call this later for plot the functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_(estimated_y):\n",
    "    X1 = np.arange(0, 1, 0.01)\n",
    "    X2 = np.arange(0, 1, 0.01)\n",
    "    X1,X2 = np.meshgrid(X1,X2)   \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(X1,X2,estimated_y , rstride=8, cstride=8,cmap=cm.coolwarm,linewidth=0.01)\n",
    "    plt.show()    \n",
    "    return '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to solve some highly non-linear non-convex problems and for this the optimization routine can be difficult, but since the function is coercive we know that the global minimum exist.\n",
    "Also for this problem i will use three type of optimization algorithm that already implemented in SciPy:\n",
    "\n",
    "1) quasi-Newton method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS)\n",
    "2) conjugate gradient algorithm by Polak, Polyak and Ribiere (CG-PPR)\n",
    "3) stochastic global optimization algorithm basin-hopping (BH)\n",
    "\n",
    "The first one use an approximation of the hessian matrix using first derivative only. Can be expensive in really high dimensional space and we can't ensure the convergence to the global optimum. The CG-PPR method uses also only first derivatives and no global convergence is not avaiable for non-convex problems. Basin-hopping is a stochastic global optimization algorithm that at every step compute a random perturbation of the coordinates and than compute a local minimization and finally evaluate the new coordinate based on the value of the objective function.\n",
    "Below we have many optimization routines and the mean squared error for the test and the training set based on the parameters found by the optimization algorithm. I choose the number of neurons N : 1,2 and the regularization parameter Âµ for every N will be 0.01 2 and 20 ; finally i choose the Gaussian as my RBF.\n",
    "\n",
    "\\vspace{5mm}\n",
    "\n",
    "N = 1 Âµ = 0.01\n",
    "\n",
    "\\vspace{5mm}\n",
    "\n",
    "In SciPy the default unconstrained optimization algorithm is the BFCG :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 16\n",
      "     nfev: 80\n",
      " hess_inv: array([[ 0.07333106, -0.02474395, -0.03717002],\n",
      "       [-0.02474395,  0.04890341, -0.00772187],\n",
      "       [-0.03717002, -0.00772187,  0.05020527]])\n",
      "      fun: 3.5569952672804264\n",
      "        x: array([ 1.43427663,  0.13062722,  0.06302914])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ -1.31130219e-06,  -1.75833702e-06,  -1.90734863e-06])\n",
      "0.0136489868164\n"
     ]
    }
   ],
   "source": [
    "function_1 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "                        + (x2_train-c[2])**2))**2))) - y_train)**2)) + 0.005*(c[1]**2 + c[2]**2 + c[0]**2)\n",
    "\n",
    "start = timer()\n",
    "opt_result = minimize(function_1 ,x0=(0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "Now we compute the CG-PPR specyfing 'CG' in minimize :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 37\n",
      "    nfev: 185\n",
      "     fun: 3.556995267281947\n",
      "       x: array([ 1.43427702,  0.13062733,  0.06302888])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([  7.59959221e-06,   5.39422035e-06,   8.94069672e-07])\n",
      "0.0290009975433\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_1 ,x0=(0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "For compute the BH we must to say what kind of local minimization we want to use, i have choosen the BFGS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 16305\n",
      " minimization_failures: 0\n",
      "                   fun: 3.556995267280356\n",
      "                     x: array([ 1.43427662,  0.13062726,  0.06302917])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 3261\n",
      "                   nit: 200\n",
      "1.44948196411\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_1, x0=(0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "Finally we compute the MSE for the training and test set : $MSE =\\frac{1}{n}\\sum_{i = 1}^{n}\\left ( \\hat{y}-y \\right )^{2}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.128012219145\n",
      "The training error is 0.0886651084845\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N1(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N1(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 1  Âµ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 1\n",
      "     nfev: 5\n",
      " hess_inv: array([[1, 0, 0],\n",
      "       [0, 1, 0],\n",
      "       [0, 0, 1]])\n",
      "      fun: 41.791063464266941\n",
      "        x: array([0, 0, 0])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ 0.,  0.,  0.])\n",
      "0.000909805297852\n"
     ]
    }
   ],
   "source": [
    "function_2 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "                              + 40000*(x2_train-c[2])**2))**2))) - y_train)**2)) + (c[1]**2 + c[2]**2 + c[0]**2)\n",
    "start = timer()\n",
    "opt_result = minimize(function_2 ,x0=(0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 1\n",
      "    nfev: 5\n",
      "     fun: 41.791063464266941\n",
      "       x: array([0, 0, 0])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([ 0.,  0.,  0.])\n",
      "0.000933170318604\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_2 ,x0=(0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_2, x0=(0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 1.29770984\n",
    "center = np.array([0.16821349, 0.1278833])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_(estimated_y_N1(w,center,x1,x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.121759028193\n",
      "The training error is 0.09245576967\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N1(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N1(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 1  Âµ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 13\n",
      "     nfev: 65\n",
      " hess_inv: array([[ 0.0160662 , -0.0023482 , -0.0027536 ],\n",
      "       [-0.0023482 ,  0.01752573, -0.00126905],\n",
      "       [-0.0027536 , -0.00126905,  0.01624674]])\n",
      "      fun: 16.28350356715417\n",
      "        x: array([ 0.89623888,  0.20821942,  0.20558905])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ -7.15255737e-07,  -5.96046448e-06,   3.33786011e-06])\n",
      "0.0091450214386\n"
     ]
    }
   ],
   "source": [
    "function_3 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "                              + (x2_train-c[2])**2))**2))) - y_train)**2)) + 10*(c[1]**2 + c[2]**2 + c[0]**2)\n",
    "start = timer()\n",
    "opt_result = minimize(function_3 ,x0=(0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 19\n",
      "    nfev: 95\n",
      "     fun: 16.283503567153733\n",
      "       x: array([ 0.89623889,  0.20821952,  0.20558899])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([  0.00000000e+00,   2.38418579e-07,  -2.38418579e-07])\n",
      "0.0121290683746\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_3 ,x0=(0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 12520\n",
      " minimization_failures: 0\n",
      "                   fun: 16.28350356715373\n",
      "                     x: array([ 0.8962389 ,  0.20821952,  0.205589  ])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 2504\n",
      "                   nit: 200\n",
      "1.49074602127\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_3 , x0=(0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w =  0.8962389 \n",
    "center = np.array([0.20821952, 0.205589])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.168427467263\n",
      "The training error is 0.184870996353\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N1(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N1(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 2  Âµ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 15\n",
      "     nfev: 120\n",
      " hess_inv: array([[ 0.51866448, -0.01173414, -0.01913019, -0.48128225, -0.01162955,\n",
      "        -0.0191295 ],\n",
      "       [-0.01173414,  0.54890949, -0.00907399, -0.01182352, -0.45126456,\n",
      "        -0.0090758 ],\n",
      "       [-0.01913019, -0.00907399,  0.55143974, -0.01914178, -0.00909998,\n",
      "        -0.44855913],\n",
      "       [-0.48128225, -0.01182352, -0.01914178,  0.51877102, -0.0117187 ,\n",
      "        -0.01914108],\n",
      "       [-0.01162955, -0.45126456, -0.00909998, -0.0117187 ,  0.54856232,\n",
      "        -0.00910178],\n",
      "       [-0.0191295 , -0.0090758 , -0.44855913, -0.01914108, -0.00910178,\n",
      "         0.551442  ]])\n",
      "      fun: 3.551955232554746\n",
      "        x: array([ 0.71743164,  0.13040013,  0.06274195,  0.71743172,  0.13040024,\n",
      "        0.062742  ])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([  2.38418579e-07,   1.19209290e-07,   4.47034836e-07,\n",
      "         2.68220901e-07,   0.00000000e+00,   4.17232513e-07])\n",
      "0.0238049030304\n"
     ]
    }
   ],
   "source": [
    "function_4 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum((((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2))) + (c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 + (x2_train-c[5])**2))**2))))- y_train)**2)) \\\n",
    "+ (0.005)*(c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 + c[3]**2)\n",
    "\n",
    "start = timer()\n",
    "opt_result = minimize(function_4 ,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end  = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 29\n",
      "    nfev: 232\n",
      "     fun: 3.551955232560182\n",
      "       x: array([ 0.717432  ,  0.13040025,  0.06274121,  0.717432  ,  0.13040025,\n",
      "        0.06274121])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([  1.40070915e-06,  -3.57627869e-07,  -6.88433647e-06,\n",
      "         1.40070915e-06,  -3.57627869e-07,  -6.88433647e-06])\n",
      "0.041512966156\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_4 ,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end  = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 67463\n",
      " minimization_failures: 1\n",
      "                   fun: 3.3634897353964988\n",
      "                     x: array([ 0.54815865,  1.04100417,  0.28684699,  1.69607352, -0.40996409,\n",
      "       -0.02295618])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 8431\n",
      "                   nit: 200\n",
      "11.5169739723\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_4, x0=(0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "In this case local minimization don't reach the global optimum for this reason we use the solution from the BH algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([0.54815865,1.69607352])\n",
    "center = np.array([1.04100417,0.28684699,-0.40996409,-0.02295618])\n",
    "estimated_y_N2 = lambda w,center,x1,x2 :  w[0]*(np.exp(-1*(np.sqrt((x1-center[0])**2\n",
    "                                        + (x2-center[1])**2))**2)) + w[1]*(np.exp(-1*(np.sqrt((x1-center[2])**2\n",
    "                                        + (x2-center[3])**2))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.106728440949\n",
      "The training error is 0.0835232794212\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N2(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N2(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 2  Âµ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 16\n",
      "     nfev: 128\n",
      " hess_inv: array([[ 0.5128415 , -0.00819957, -0.01167853, -0.48705387, -0.00867198,\n",
      "        -0.01160053],\n",
      "       [-0.00819957,  0.53485143, -0.00462282, -0.00851004, -0.46378075,\n",
      "        -0.00482137],\n",
      "       [-0.01167853, -0.00462282,  0.53542773, -0.0114084 , -0.00581492,\n",
      "        -0.46437708],\n",
      "       [-0.48705387, -0.00851004, -0.0114084 ,  0.51304544, -0.00895972,\n",
      "        -0.01133243],\n",
      "       [-0.00867198, -0.46378075, -0.00581492, -0.00895972,  0.53749013,\n",
      "        -0.00600516],\n",
      "       [-0.01160053, -0.00482137, -0.46437708, -0.01133243, -0.00600516,\n",
      "         0.53581812]])\n",
      "      fun: 4.575528724912473\n",
      "        x: array([ 0.68457914,  0.13798288,  0.09381353,  0.68457929,  0.13798228,\n",
      "        0.09381369])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ -7.15255737e-07,   6.55651093e-07,  -5.36441803e-07,\n",
      "        -2.38418579e-07,  -1.25169754e-06,   4.17232513e-07])\n",
      "0.0264451503754\n"
     ]
    }
   ],
   "source": [
    "function_5 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2)) + c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 + (x2_train-c[5])**2))**2))) - y_train)**2)) \\\n",
    "+ (c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 + c[3]**2)\n",
    "start = timer()\n",
    "opt_result = minimize(function_5 ,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 19\n",
      "    nfev: 152\n",
      "     fun: 4.575528724917588\n",
      "       x: array([ 0.68457934,  0.13798199,  0.09381359,  0.68457933,  0.13798199,\n",
      "        0.09381359])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([ -5.06639481e-06,  -9.95397568e-06,  -3.33786011e-06,\n",
      "        -5.06639481e-06,  -9.95397568e-06,  -3.33786011e-06])\n",
      "0.0277318954468\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_5 ,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end  = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 39840\n",
      " minimization_failures: 0\n",
      "                   fun: 4.575528724912127\n",
      "                     x: array([ 0.68457928,  0.1379826 ,  0.0938136 ,  0.68457918,  0.1379826 ,\n",
      "        0.09381358])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 4980\n",
      "                   nit: 200\n",
      "6.76513886452\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_5, x0=(0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([0.68457928,0.68457918])\n",
    "objective_function = 5.230962\n",
    "center = np.array([0.1379826,0.0938136,0.1379826,0.09381358])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.126193187063\n",
      "The training error is 0.0895637726369\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N2(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N2(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 2  Âµ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 12\n",
      "     nfev: 96\n",
      " hess_inv: array([[ 0.50576434, -0.00186363, -0.00211638, -0.49423566, -0.00186363,\n",
      "        -0.00211638],\n",
      "       [-0.00186363,  0.51299237, -0.00080801, -0.00186363, -0.48700763,\n",
      "        -0.00080801],\n",
      "       [-0.00211638, -0.00080801,  0.51199766, -0.00211638, -0.00080801,\n",
      "        -0.48800234],\n",
      "       [-0.49423566, -0.00186363, -0.00211638,  0.50576434, -0.00186363,\n",
      "        -0.00211638],\n",
      "       [-0.00186363, -0.48700763, -0.00080801, -0.00186363,  0.51299237,\n",
      "        -0.00080801],\n",
      "       [-0.00211638, -0.00080801, -0.48800234, -0.00211638, -0.00080801,\n",
      "         0.51199766]])\n",
      "      fun: 11.910333487473952\n",
      "        x: array([ 0.552897  ,  0.13248794,  0.12736661,  0.552897  ,  0.13248794,\n",
      "        0.12736661])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([  9.53674316e-07,   4.76837158e-07,   5.48362732e-06,\n",
      "         9.53674316e-07,   4.76837158e-07,   5.48362732e-06])\n",
      "0.0244917869568\n"
     ]
    }
   ],
   "source": [
    "function_6 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2)) + c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 + (x2_train-c[5])**2))**2))) - y_train)**2)) \\\n",
    "+ 10*(c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 + c[3]**2)\n",
    "start = timer()\n",
    "opt_result = minimize(function_6 ,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 20\n",
      "    nfev: 160\n",
      "     fun: 11.910333487473968\n",
      "       x: array([ 0.55289701,  0.13248804,  0.12736638,  0.55289701,  0.13248804,\n",
      "        0.12736638])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([ -1.07288361e-06,   3.33786011e-06,  -3.69548798e-06,\n",
      "        -1.07288361e-06,   3.33786011e-06,  -3.69548798e-06])\n",
      "0.0335850715637\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_6,x0=(0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end  = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 31936\n",
      " minimization_failures: 0\n",
      "                   fun: 11.910333487473295\n",
      "                     x: array([ 0.55289701,  0.13248794,  0.12736647,  0.55289703,  0.13248795,\n",
      "        0.12736648])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 3992\n",
      "                   nit: 200\n",
      "5.4465470314\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_6, x0=(0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([0.55289701,0.55289703])\n",
    "center = np.array([0.13248794,0.12736647,0.13248795,0.12736648])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.147681134688\n",
      "The training error is 0.128023142562\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N2(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N2(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 4  Âµ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 13\n",
      "     nfev: 182\n",
      " hess_inv: array([[ 0.75464305, -0.00597207, -0.00924527, -0.2453601 , -0.00596433,\n",
      "        -0.00924227, -0.24536009, -0.00599135, -0.00925228, -0.24536094,\n",
      "        -0.00598443, -0.00925312],\n",
      "       [-0.00597207,  0.79843313, -0.00879992, -0.00592282, -0.20169716,\n",
      "        -0.00885112, -0.00592283, -0.20123597, -0.00868031, -0.00591342,\n",
      "        -0.20135621, -0.00867091],\n",
      "       [-0.00924527, -0.00879992,  0.79922254, -0.00923798, -0.008843  ,\n",
      "        -0.20078481, -0.00923802, -0.00866751, -0.20072384, -0.00924852,\n",
      "        -0.00872104, -0.20073435],\n",
      "       [-0.2453601 , -0.00592282, -0.00923798,  0.75463674, -0.00591524,\n",
      "        -0.00923498, -0.24536324, -0.00594154, -0.00924475, -0.24536418,\n",
      "        -0.00593485, -0.00924567],\n",
      "       [-0.00596433, -0.20169716, -0.008843  , -0.00591524,  0.79817351,\n",
      "        -0.00889402, -0.00591525, -0.20136924, -0.00872458, -0.00590561,\n",
      "        -0.20148828, -0.00871495],\n",
      "       [-0.00924227, -0.00885112, -0.20078481, -0.00923498, -0.00889402,\n",
      "         0.79920785, -0.00923502, -0.00871933, -0.20073145, -0.00924543,\n",
      "        -0.0087726 , -0.20074188],\n",
      "       [-0.24536009, -0.00592283, -0.00923802, -0.24536324, -0.00591525,\n",
      "        -0.00923502,  0.75463678, -0.00594155, -0.00924479, -0.24536416,\n",
      "        -0.00593486, -0.00924571],\n",
      "       [-0.00599135, -0.20123597, -0.00866751, -0.00594154, -0.20136924,\n",
      "        -0.00871933, -0.00594155,  0.79910383, -0.00854435, -0.00593276,\n",
      "        -0.20101997, -0.00853557],\n",
      "       [-0.00925228, -0.00868031, -0.20072384, -0.00924475, -0.00872458,\n",
      "        -0.20073145, -0.00924479, -0.00854435,  0.79933119, -0.00925551,\n",
      "        -0.00859929, -0.20067956],\n",
      "       [-0.24536094, -0.00591342, -0.00924852, -0.24536418, -0.00590561,\n",
      "        -0.00924543, -0.24536416, -0.00593276, -0.00925551,  0.7546349 ,\n",
      "        -0.00592584, -0.00925644],\n",
      "       [-0.00598443, -0.20135621, -0.00872104, -0.00593485, -0.20148828,\n",
      "        -0.0087726 , -0.00593486, -0.20101997, -0.00859929, -0.00592584,\n",
      "         0.79885764, -0.00859028],\n",
      "       [-0.00925312, -0.00867091, -0.20073435, -0.00924567, -0.00871495,\n",
      "        -0.20074188, -0.00924571, -0.00853557, -0.20067956, -0.00925644,\n",
      "        -0.00859028,  0.79930969]])\n",
      "      fun: 3.549590056336123\n",
      "        x: array([ 0.35880966,  0.13020007,  0.06256882,  0.35880955,  0.13020039,\n",
      "        0.06256893,  0.35880961,  0.13019915,  0.06256854,  0.35880961,\n",
      "        0.13019942,  0.06256857])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ -2.08616257e-07,  -1.49011612e-07,   1.78813934e-07,\n",
      "        -2.38418579e-07,  -2.98023224e-07,   1.49011612e-07,\n",
      "        -2.08616257e-07,   1.78813934e-07,   3.27825546e-07,\n",
      "        -2.08616257e-07,   1.19209290e-07,   2.68220901e-07])\n",
      "0.0594398975372\n"
     ]
    }
   ],
   "source": [
    "function_7 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2))+ c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 \n",
    "+ (x2_train-c[5])**2))**2))+ c[6]*(np.exp(-1*(np.sqrt((x1_train-c[7])**2 \n",
    "+ (x2_train-c[8])**2))**2))+ c[9]*(np.exp(-1*(np.sqrt((x1_train-c[10])**2 + (x2_train-c[11])**2))**2))) - y_train)**2)) \\\n",
    "+ (0.005)*(c[9]**2 + c[10]**2 + c[11]**2 + c[6]**2 + c[7]**2 + c[8]**2 + c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 \\\n",
    "           + c[3]**2)\n",
    "\n",
    "start = timer()\n",
    "opt_result = minimize(function_7,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 38\n",
      "    nfev: 532\n",
      "     fun: 3.5495900563769096\n",
      "       x: array([ 0.35881014,  0.13019887,  0.06256706,  0.35881014,  0.13019887,\n",
      "        0.06256706,  0.35881015,  0.13019887,  0.06256706,  0.35881015,\n",
      "        0.13019887,  0.06256706])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([  4.88758087e-06,  -5.48362732e-06,  -8.10623169e-06,\n",
      "         4.88758087e-06,  -5.48362732e-06,  -8.10623169e-06,\n",
      "         4.88758087e-06,  -5.48362732e-06,  -8.10623169e-06,\n",
      "         4.88758087e-06,  -5.51342964e-06,  -8.10623169e-06])\n",
      "0.16748213768\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_7,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 328930\n",
      " minimization_failures: 0\n",
      "                   fun: 3.2750758019302637\n",
      "                     x: array([ 2.0667494 , -0.45076649,  0.41033837,  0.65224013,  0.65291665,\n",
      "        0.25103113,  1.15048194,  0.58606559,  1.84004456, -1.4580863 ,\n",
      "       -0.05603354,  1.21173346])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 23495\n",
      "                   nit: 200\n",
      "92.1903629303\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_7, x0=(0,0,0,0,0,0,0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([2.0667494,0.65224013,1.15048194,-1.4580863])\n",
    "center = np.array([-0.45076649,0.41033837,0.65291665,0.25103113,0.58606559, 1.84004456,-0.05603354,1.21173346])\n",
    "estimated_y_N4 = lambda w,center,x1,x2 : (w[0]*(np.exp(-1*(np.sqrt((x1-center[0])**2 + (x2-center[1])**2))**2)) \n",
    "                                          + w[1]*(np.exp(-1*(np.sqrt((x1-center[2])**2 + (x2-center[3])**2))**2)) \n",
    "                                          + w[2]*(np.exp(-1*(np.sqrt((x1-center[4])**2 + (x2-center[5])**2))**2)) \n",
    "                                          + w[3]*(np.exp(-1*(np.sqrt((x1-center[6])**2 + (x2-center[7])**2))**2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.109018301081\n",
      "The training error is 0.0801008882979\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N4(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N4(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 4  Âµ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 14\n",
      "     nfev: 196\n",
      " hess_inv: array([[  7.52907816e-01,  -1.00026131e-03,  -5.51972349e-03,\n",
      "         -2.47368993e-01,  -1.02097741e-03,  -4.91766415e-03,\n",
      "         -2.46233921e-01,  -9.30977549e-04,  -7.37480579e-03,\n",
      "         -2.45201993e-01,  -2.96661084e-03,  -5.31206522e-03],\n",
      "       [ -1.00026131e-03,   7.79747143e-01,  -7.27485765e-03,\n",
      "          7.17249123e-04,  -2.20053148e-01,  -1.09387691e-02,\n",
      "         -6.18202041e-03,  -2.20683057e-01,   3.95052764e-03,\n",
      "         -1.20890573e-02,  -2.08905975e-01,  -8.56377509e-03],\n",
      "       [ -5.51972349e-03,  -7.27485765e-03,   7.84161704e-01,\n",
      "         -5.46088123e-03,  -7.25838837e-03,  -2.15954158e-01,\n",
      "         -5.67812568e-03,  -7.28968429e-03,  -2.15491801e-01,\n",
      "         -5.81373164e-03,  -7.00101290e-03,  -2.15882511e-01],\n",
      "       [ -2.47368993e-01,   7.17249123e-04,  -5.46088123e-03,\n",
      "          7.52253138e-01,   6.90158640e-04,  -4.63779353e-03,\n",
      "         -2.46195012e-01,   8.11780364e-04,  -7.99785769e-03,\n",
      "         -2.44778319e-01,  -1.98102528e-03,  -5.17744553e-03],\n",
      "       [ -1.02097741e-03,  -2.20053148e-01,  -7.25838837e-03,\n",
      "          6.90158640e-04,   7.80146561e-01,  -1.09079516e-02,\n",
      "         -6.18201335e-03,  -2.20481760e-01,   3.92238712e-03,\n",
      "         -1.20619995e-02,  -2.08757238e-01,  -8.54253087e-03],\n",
      "       [ -4.91766415e-03,  -1.09387691e-02,  -2.15954158e-01,\n",
      "         -4.63779353e-03,  -1.09079516e-02,   7.83446981e-01,\n",
      "         -5.76575544e-03,  -1.10088190e-02,  -2.14117912e-01,\n",
      "         -6.74006450e-03,  -9.06899620e-03,  -2.16164110e-01],\n",
      "       [ -2.46233921e-01,  -6.18202041e-03,  -5.67812568e-03,\n",
      "         -2.46195012e-01,  -6.18201335e-03,  -5.76575544e-03,\n",
      "          7.53639643e-01,  -6.19162085e-03,  -5.40614284e-03,\n",
      "         -2.46524861e-01,  -5.87146015e-03,  -5.70721063e-03],\n",
      "       [ -9.30977549e-04,  -2.20683057e-01,  -7.28968429e-03,\n",
      "          8.11780364e-04,  -2.20481760e-01,  -1.10088190e-02,\n",
      "         -6.19162085e-03,   7.78880436e-01,   4.10607530e-03,\n",
      "         -1.21948159e-02,  -2.09153263e-01,  -8.59753304e-03],\n",
      "       [ -7.37480579e-03,   3.95052764e-03,  -2.15491801e-01,\n",
      "         -7.99785769e-03,   3.92238712e-03,  -2.14117912e-01,\n",
      "         -5.40614284e-03,   4.10607530e-03,   7.80260033e-01,\n",
      "         -2.95664264e-03,  -6.95111476e-04,  -2.15024695e-01],\n",
      "       [ -2.45201993e-01,  -1.20890573e-02,  -5.81373164e-03,\n",
      "         -2.44778319e-01,  -1.20619995e-02,  -6.74006450e-03,\n",
      "         -2.46524861e-01,  -1.21948159e-02,  -2.95664264e-03,\n",
      "          7.51864959e-01,  -9.02509478e-03,  -6.13135691e-03],\n",
      "       [ -2.96661084e-03,  -2.08905975e-01,  -7.00101290e-03,\n",
      "         -1.98102528e-03,  -2.08757238e-01,  -9.06899620e-03,\n",
      "         -5.87146015e-03,  -2.09153263e-01,  -6.95111476e-04,\n",
      "         -9.02509478e-03,   7.97197416e-01,  -7.74105721e-03],\n",
      "       [ -5.31206522e-03,  -8.56377509e-03,  -2.15882511e-01,\n",
      "         -5.17744553e-03,  -8.54253087e-03,  -2.16164110e-01,\n",
      "         -5.70721063e-03,  -8.59753304e-03,  -2.15024695e-01,\n",
      "         -6.13135691e-03,  -7.74105721e-03,   7.84016454e-01]])\n",
      "      fun: 4.132027353139028\n",
      "        x: array([ 0.35601457,  0.11004979,  0.06863307,  0.35601486,  0.11004985,\n",
      "        0.06863245,  0.35601372,  0.11004972,  0.06863495,  0.35601279,\n",
      "        0.11005157,  0.06863283])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([  5.06639481e-06,  -2.38418579e-07,   5.96046448e-07,\n",
      "         5.84125519e-06,  -1.19209290e-07,  -1.13248825e-06,\n",
      "         2.68220901e-06,  -5.96046448e-07,   5.84125519e-06,\n",
      "         4.76837158e-07,   4.35113907e-06,   1.19209290e-07])\n",
      "0.0637500286102\n"
     ]
    }
   ],
   "source": [
    "function_8 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2))+ c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 \n",
    "+ (x2_train-c[5])**2))**2))+ c[6]*(np.exp(-1*(np.sqrt((x1_train-c[7])**2 \n",
    "+ (x2_train-c[8])**2))**2))+ c[9]*(np.exp(-1*(np.sqrt((x1_train-c[10])**2 + (x2_train-c[11])**2))**2))) - y_train)**2)) \\\n",
    "+ (c[9]**2 + c[10]**2 + c[11]**2 + c[6]**2 + c[7]**2 + c[8]**2 + c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 \\\n",
    "           + c[3]**2)\n",
    "\n",
    "start = timer()\n",
    "opt_result = minimize(function_8,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 0\n",
      " success: True\n",
      "    njev: 26\n",
      "    nfev: 364\n",
      "     fun: 4.132027353133642\n",
      "       x: array([ 0.35601413,  0.11005005,  0.06863264,  0.35601413,  0.11005005,\n",
      "        0.06863264,  0.35601413,  0.11005006,  0.06863264,  0.35601413,\n",
      "        0.11005005,  0.06863263])\n",
      " message: 'Optimization terminated successfully.'\n",
      "     jac: array([ -7.74860382e-07,  -1.96695328e-06,  -5.00679016e-06,\n",
      "        -7.74860382e-07,  -1.96695328e-06,  -5.00679016e-06,\n",
      "        -7.74860382e-07,  -1.96695328e-06,  -5.06639481e-06,\n",
      "        -8.34465027e-07,  -1.90734863e-06,  -5.00679016e-06])\n",
      "0.116698980331\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_8,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 91462\n",
      " minimization_failures: 0\n",
      "                   fun: 4.132027353127132\n",
      "                     x: array([ 0.35601397,  0.11005021,  0.06863325,  0.356014  ,  0.11005021,\n",
      "        0.06863326,  0.35601398,  0.11005019,  0.06863325,  0.35601398,\n",
      "        0.1100502 ,  0.06863324])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 6533\n",
      "                   nit: 200\n",
      "25.3624031544\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_8, x0=(0,0,0,0,0,0,0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([0.35601397,0.356014,0.35601398,0.35601398])\n",
    "objective_function = 5.0240\n",
    "center = np.array([ 0.11005021,0.06863325,0.11005021,0.06863326,0.11005019,0.06863325,0.1100502,0.06863324])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.130744563795\n",
      "The training error is 0.088943931247\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N4(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N4(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "N = 4  Âµ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 17\n",
      "     nfev: 238\n",
      " hess_inv: array([[  7.41702739e-01,   2.05800080e-02,  -2.87128464e-02,\n",
      "         -2.09486712e-01,   3.87982587e-03,   8.47692961e-03,\n",
      "         -2.11322880e-01,   2.34700287e-03,   8.72973197e-03,\n",
      "         -3.13295606e-01,  -3.10234015e-02,   6.77747162e-03],\n",
      "       [  2.05800080e-02,   4.34263813e-01,   3.19773642e-01,\n",
      "          5.07394555e-03,  -1.68726126e-01,  -3.78333531e-02,\n",
      "          2.23192728e-03,  -1.61111901e-01,  -4.60144844e-02,\n",
      "         -3.23080891e-02,  -6.96047149e-02,  -2.38564170e-01],\n",
      "       [ -2.87128464e-02,   3.19773642e-01,   4.26348672e-01,\n",
      "          7.47685238e-03,  -3.67999597e-02,  -1.67867638e-01,\n",
      "          9.10779217e-03,  -4.61273613e-02,  -1.61008335e-01,\n",
      "          7.46580006e-03,  -2.40103780e-01,  -6.42481918e-02],\n",
      "       [ -2.09486712e-01,   5.07394555e-03,   7.47685238e-03,\n",
      "          5.64117750e-01,  -1.27072620e-02,   3.66106951e-03,\n",
      "         -4.26420574e-01,  -9.64228301e-03,   4.21831803e-03,\n",
      "          7.96258183e-02,   1.39342823e-02,  -2.07381850e-02],\n",
      "       [  3.87982587e-03,  -1.68726126e-01,  -3.67999597e-02,\n",
      "         -1.27072620e-02,   6.56591229e-01,  -8.46174851e-02,\n",
      "         -1.03965165e-02,  -3.41186279e-01,  -7.96770649e-02,\n",
      "          1.52632931e-02,  -1.10472592e-01,   1.97122678e-01],\n",
      "       [  8.47692961e-03,  -3.78333531e-02,  -1.67867638e-01,\n",
      "          3.66106951e-03,  -8.46174851e-02,   6.55199145e-01,\n",
      "          4.23556350e-03,  -7.96739069e-02,  -3.42691911e-01,\n",
      "         -2.11644545e-02,   1.98639271e-01,  -1.11065107e-01],\n",
      "       [ -2.11322880e-01,   2.23192728e-03,   9.10779217e-03,\n",
      "         -4.26420574e-01,  -1.03965165e-02,   4.23556350e-03,\n",
      "          5.82532361e-01,  -7.47310734e-03,   4.66426162e-03,\n",
      "          6.31053796e-02,   1.24849757e-02,  -2.35694723e-02],\n",
      "       [  2.34700287e-03,  -1.61111901e-01,  -4.61273613e-02,\n",
      "         -9.64228301e-03,  -3.41186279e-01,  -7.96739069e-02,\n",
      "         -7.47310734e-03,   6.60630558e-01,  -7.46755507e-02,\n",
      "          1.07413055e-02,  -1.22350232e-01,   1.96707802e-01],\n",
      "       [  8.72973197e-03,  -4.60144844e-02,  -1.61008335e-01,\n",
      "          4.21831803e-03,  -7.96770649e-02,  -3.42691911e-01,\n",
      "          4.66426162e-03,  -7.46755507e-02,   6.59105014e-01,\n",
      "         -2.22685643e-02,   1.97327375e-01,  -1.22241498e-01],\n",
      "       [ -3.13295606e-01,  -3.23080891e-02,   7.46580006e-03,\n",
      "          7.96258183e-02,   1.52632931e-02,  -2.11644545e-02,\n",
      "          6.31053796e-02,   1.07413055e-02,  -2.22685643e-02,\n",
      "          1.77663592e-01,   3.71386460e-04,   3.26527309e-02],\n",
      "       [ -3.10234015e-02,  -6.96047149e-02,  -2.40103780e-01,\n",
      "          1.39342823e-02,  -1.10472592e-01,   1.98639271e-01,\n",
      "          1.24849757e-02,  -1.22350232e-01,   1.97327375e-01,\n",
      "          3.71386460e-04,   3.37603350e-01,  -1.59020935e-01],\n",
      "       [  6.77747162e-03,  -2.38564170e-01,  -6.42481918e-02,\n",
      "         -2.07381850e-02,   1.97122678e-01,  -1.11065107e-01,\n",
      "         -2.35694723e-02,   1.96707802e-01,  -1.22241498e-01,\n",
      "          3.26527309e-02,  -1.59020935e-01,   3.31351312e-01]])\n",
      "      fun: 8.712760942445477\n",
      "        x: array([ 0.32309645,  0.06935895,  0.06404052,  0.32309657,  0.06935889,\n",
      "        0.06404054,  0.32309651,  0.06935893,  0.06404043,  0.32309641,\n",
      "        0.06935893,  0.06404038])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ -2.38418579e-07,   1.19209290e-06,   1.31130219e-06,\n",
      "         2.26497650e-06,  -7.15255737e-07,   1.19209290e-06,\n",
      "         1.43051147e-06,   4.76837158e-07,  -9.53674316e-07,\n",
      "        -2.38418579e-07,   9.53674316e-07,  -1.66893005e-06])\n",
      "0.0835711956024\n"
     ]
    }
   ],
   "source": [
    "function_9 = lambda c,x1_train,x2_train,y_train: 0.5*(np.sum(((c[0]*(np.exp(-1*(np.sqrt((x1_train-c[1])**2 \n",
    "+ (x2_train-c[2])**2))**2))+ c[3]*(np.exp(-1*(np.sqrt((x1_train-c[4])**2 \n",
    "+ (x2_train-c[5])**2))**2))+ c[6]*(np.exp(-1*(np.sqrt((x1_train-c[7])**2 \n",
    "+ (x2_train-c[8])**2))**2))+ c[9]*(np.exp(-1*(np.sqrt((x1_train-c[10])**2 + (x2_train-c[11])**2))**2))) - y_train)**2)) \\\n",
    "+ 10*(c[9]**2 + c[10]**2 + c[11]**2 + c[6]**2 + c[7]**2 + c[8]**2 + c[1]**2 + c[2]**2 + c[4]**2 + c[5]**2 + c[0]**2 \\\n",
    "           + c[3]**2)\n",
    "\n",
    "start = timer()\n",
    "opt_result = minimize(function_9,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train))\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: 2\n",
      " success: False\n",
      "    njev: 11\n",
      "    nfev: 166\n",
      "     fun: 8.714240670181209\n",
      "       x: array([ 0.32486874,  0.07047241,  0.06501682,  0.32486875,  0.07047241,\n",
      "        0.06501682,  0.32486875,  0.07047241,  0.06501682,  0.32486875,\n",
      "        0.07047241,  0.06501682])\n",
      " message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     jac: array([ 0.32897079,  0.0738945 ,  0.07698321,  0.32897079,  0.0738945 ,\n",
      "        0.07698321,  0.32897091,  0.07389462,  0.07698321,  0.32897091,\n",
      "        0.0738945 ,  0.07698321])\n",
      "0.0536689758301\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "opt_result = minimize(function_9,x0=(0,0,0,0,0,0,0,0,0,0,0,0),args=(x1_train,x2_train,y_train),method = 'CG')\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nfev: 89110\n",
      " minimization_failures: 0\n",
      "                   fun: 8.71276094244514\n",
      "                     x: array([ 0.32309648,  0.06935891,  0.06404047,  0.32309648,  0.06935891,\n",
      "        0.06404047,  0.32309648,  0.06935891,  0.06404047,  0.32309648,\n",
      "        0.06935891,  0.06404048])\n",
      "               message: ['requested number of basinhopping iterations completed successfully']\n",
      "                  njev: 6365\n",
      "                   nit: 200\n",
      "24.9872310162\n"
     ]
    }
   ],
   "source": [
    "minimizer_kwargs = {\"method\": \"BFGS\",\"args\":(x1_train,x2_train,y_train)}\n",
    "start = timer()\n",
    "opt_result = basinhopping(function_9, x0=(0,0,0,0,0,0,0,0,0,0,0,0), minimizer_kwargs=minimizer_kwargs,niter=200)\n",
    "end = timer()\n",
    "print opt_result\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([0.32309648,0.32309648,0.32309648,0.32309648])\n",
    "center = np.array([ 0.06935891,0.06404047,0.06935891,0.06404047,0.06935891,0.06404047, 0.06935891,0.06404048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.145646643815\n",
      "The training error is 0.104515847658\n"
     ]
    }
   ],
   "source": [
    "print \"The test error is \"+str(mean_squared_error(y_test, estimated_y_N4(w,center,x1_test,x2_test)))\n",
    "print \"The training error is \"+str(mean_squared_error(y_train, estimated_y_N4(w,center,x1_train,x2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "Now put together all the result and comment the behaviour of the error changing the parameters of the function by plotting the test and training error for every choice of the parameter:\n",
    "\\vspace{5mm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xaa05b28c>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdQAAACQCAYAAACxmZqiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xac693b6c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdQAAACQCAYAAACxmZqiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+pcJKyiuX4IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaa133e0c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_err_N1 = [0.0886651,0.0924557,0.1848709]\n",
    "test_err_N1 = [0.1280122,0.1217590,0.1684274]\n",
    "train_err_N2 = [0.0835232,0.0895637,0.1280231]\n",
    "test_err_N2 = [0.1067284,0.1261931,0.1476811]\n",
    "train_err_N4 = [0.0801008,0.08894393,0.10451584]\n",
    "test_err_N4 = [0.10901801,0.13074456,0.14564664]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(test_err_N1,label = 'N=1')\n",
    "ax.plot(test_err_N2,label = 'N=2')\n",
    "ax.plot(test_err_N4,label = 'N=4')\n",
    "ax.set_title('Test MSE/regularization parameter behaviour')\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.3, 0.5))\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.set_title('Training MSE/regularization parameter behaviour')\n",
    "ax2.plot(train_err_N1,label = 'N=1')\n",
    "ax2.plot(train_err_N2,label = 'N=2')\n",
    "ax2.plot(train_err_N4,label = 'N=4')\n",
    "ax2.legend(loc='center right', bbox_to_anchor=(1.3, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "Above we have the behaviour of the test and training MSE changing the parameter Âµ changing  (that for simplicity i have assumed that Âµ1 = Âµ2 ). The regularization parameter Âµ has the task to penalize the error function and try to improve the smoothness of the function. Infact we know that the important stuff in machine learning is to reach a good test error instead to reach training error equal to zero. In our case we can see that the training error always increase as increase Âµ. For N = 1 we have an insteresting decrease of the test error but when we penalize the function too much the test MSE increase really together with the training error.\n",
    "\n",
    "\\vspace{5mm}\n",
    "\n",
    "Now we'll see the behaviour of the errors increasing the complexity of the model therefore the number of the parameters for every choice of Âµ.\n",
    "\n",
    "\\vspace{5mm}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_m01 = [0.0886651,0.0835232,0.0801008]\n",
    "test_err_m01 = [0.1280122,0.1067284,0.10901801]\n",
    "train_err_m2 = [0.0924557,0.0895637,0.08894393]\n",
    "test_err_m2 = [0.1217590,0.1261931,0.13074456]\n",
    "train_err_m20 = [0.1848709,0.1280231,0.10451584]\n",
    "test_err_m20 = [0.1684274,0.1476811,0.14564664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa9dcbe6c>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACQCAYAAADk1Lu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9aef72c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAACQCAYAAAD6MUlPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFfn/CiGsbBWDB1YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9f89dcc>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACQCAYAAADk1Lu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8FPW5+PHPQwjXcL/KJSQQQgDBpFLUWjW1tuDd4pUq\narY9tp6jx1N7ejvVqr++attfe1pr9fc71rIBBBUVqRewaluwUBWlJIiQAIFwRyAQSEKAkOQ5f8wE\nNptNdjfZW5Ln/XrtK7s735n9zjA8M/Od7zxfUVWMMcZ0Dl3iXQFjjDGxY0HfGGM6EQv6xhjTiVjQ\nN8aYTsSCvjHGdCIW9I0xphOxoG86DBFZLiJzIl3WmI7Egn4CE5EqEal0X/UiUu3zeXYrlrdSRL7R\nwvQ093fW+X0/WERqRKTU57svisj7InJURA6LyGoRmeZOu1tE6nzqWikiFSIy3Gf+ESKyx69Mm9ZR\nVa9S1eciXTYcIpLrrserft+f536/wue760WkUESOicghEfmriKS50x4VkdN+2+dIpOsbKyIyRERe\nEJG97j6zWkSm+5X5uojsdPf7pSIyIF717cgs6CcwVU1R1T6q2gfYCVzT8FlVX2jNIkMs11NEJvt8\n/jqwvWF+EekLvAn8DhgAjAQeA075zPMPn7r2UdW+qvqZz/SrgOW+ZVpaRxHpGua6xtMh4EIRGejz\n3V3AFs5uwwxgPvAdVe0HpANPA3VueQVe8NuGvstrb1KANcDncPaZ+cAyEekN4O5v/wPcDgwDqoH/\nF5+qdmwW9NshEekiIj8UkRIRKRORxQ1nRSLSQ0QWut+Xi8hHIjJURH4GXAI85Z41PtnCTzyHE6Qa\nzAEWAOJ+zgRUVRer46SqvquqG3yrGWQ1rgKWt7COue6VwPdFZD8wV0T6i8ibInJQRI6IyBsiMtJn\nnjNXMu7VxmoR+ZVbdruIzGxl2XQR+bt7tfKuiDwtIi1dJdQAfwJuc+dPAm4BFvlsl2ygVFVX4GzM\nKlV9VVV3+2y/YNuwVdyriJdF5Dl3nT4RkfEi8iMROeCebX8lkr+pqqWq+oSqHnD3mWeBbjj7EjjB\n/nVVXa2qx4GHgVkNBwUTORb026f7geuAS4FzgHKcs0RwgnVfYBQwEPgWcEJVfwysAv7NPWv89xaW\nvwi4TRyTOHuW1mALUCci80RkZriX4SKSjHMAejdI0WE4Z4Wp7np0Aea6n1OBE8BTPuWVxlcz04Fi\nYBDwf915W1P2eeBDnO35KHAHwa+angPudN/PAD4F9vlMXwdkichv3ANcSpDlRdo1OAfyAUABZ/8t\nRgA/BZ5pbkb3wFvezOv1UH5cRLJxgn6J+9UkYH3DdFXdjnPlmNl0btMWFvTbp28BD6nqPlU9jdO0\ncpN7RlmDE7jGu2dUBapa6TNvKGePe4DNwFdwAtcC34mqWgF8ESfwPQscFJHXRGSoT7EL/YLBVp9p\nlwLr3TO6ltQDj6jqafdq4oiqLnXfVwGPA5e1MP9OVZ2rToKpBcA5fnUMWlZEUoFpwE9UtVZV/wG8\nTpDtqKofAANFJBNnG873m74dyMVpGnsJOCQi+X5ntrf4bcO/tvSbYfq7e3VWB7yCs8/8wv28GEhz\nm/ECrds1qjqgmdd1wX7YXe5zwKM++2YKcMyvaAXQp5XrZ5phQb99SgOWNgQDYBNQCwzF+c/0NvCi\ne9Psl37t4aG06zcEvjycJorn8AtyqlqsqnmqOho4F+cM8QmfIh/6BYPxPtOuApaFUI9DqlrT8EFE\neonIMyKyQ0SOAe8B/USkuQB85h6Cqla7b5s7o26u7AjgiKqe9Cm7m9A8h3NVlgsspek2XKOqt6rq\nUJwrn0uBH/sUWey3Db8c4u+G4qDP+xNAmZ7NvnjC/Rvxqw8R6Qm8Abyvqr/0mVQF9PMr3g+oxESU\nBf32aRcw0y8g9FLV/e7Z6P9R1cnAF3Au4xuaGcJJqfoqTnDepqp7WiqoqptxzmTPDXHZV9JCe77v\nov0+fxfncn+6e/PzMqLY9u3aj3PG3tPnu9QQ510I3Ass8ztoNKGqa3EODL430KO1Xm1KrSsib0nj\nXkW+r2YP5iLSHedexy5V/Zbf5I3AeT5lx+E0/2xpS11NUxb026f/AR53mx4ausNd577PFZEpblNP\nJXCasz1CDgDjQvkBt+nlS8A3/aeJSJaIPNhwE1VERgOzgQ+CLVdE0oHu7oEiXCk4Z6HHxOkZ80gr\nlhEWVd0JrAUeFZFkEbkI50AaNHCqailNz96BM11evykiQ9zPWcC1OPcOoq1NBxNVvdKvV5Hv6+qA\nP+jcx3kFp1fO3QGKLAKudbdLb5z7CktCaAI0YbKg3z79Dqdd+R0RqcAJtg19nocDL+O0j24CVuI0\nMzTMd5PbQ+UJAjsTzFR1nRu4/KdVABcAa0Skyv39T3DOxBvKXSRN++lPA64mtKadRnVxPQH0BMqA\n94G3ApTxndd/WmvL3g5cBBzGCUaLce6dBK23qr6vZ7uq+v5OOc7N+A0iUomzLq/i3ERuKHtrgG04\nuIXfDVUo2ybSA218Aeff/ivAUZ91uhhAVTcB38YJ/gdw/p3/NcJ1MIBokEFU3K5rTwBJwB/92uEa\nzlDygRzgx6r63z7THsA5UxTgWVX9XWSrb9ob9/L/96r653jXpbVEZDGwSVUfi3ddjAlXi2f6bhPB\nU8BMnC5Vs0Vkol+xwzg3q37tN++5OAH/8zhtdde47XSmc1vpvtoNEZkmIuPEeT7iSpwz9D/Fu17G\ntEaw5p3pQImq7nC7Br4IXO9bQFUPuTehTvvNmwWscbvX1eH0tJgVoXqbdkpVfxXspmYCGg6swLlH\n8lvg26q6vuVZjElMwR5tH0nj7ml7cNpyQ/Ep8DP3httJnPa8j8KuoTFxpqpv4qSdMKbdCxb0W30z\nR1WLReSXwDvAcZyn/ur9y4mIjcxujDGtoKph98QK1ryzFxjt83k0ztl+qBXyquo0Vb0MOIrzlGeg\ncvaK0OuRRx6Jex060su2p23LRH21VrCgvxYYL07K3W7ArThdBQNpcsRpeOTd7U/+NZwcJsYYY+Kk\nxeYdVa0VkftwHutPAuaqapGIfMud/ow4OdI/xknyVe9205ykTm6UV0RkEM5N3n9VJ2eLMcaYOAma\no1xV38J5cMT3u2d83n9G4yYg33KXtrWCJjy5ubnxrkKHYtszcmxbJoagD2dFvQIieuL0CXp07RHX\nehhjTHsiImgUbuTGxKjfjOK+5fexbv+6Nt2gMMYY07KgQd8dJKNYRLaKyA8CTM8SkQ9E5KSIfNdv\n2o9EZKOIbBCR590se02svWctQ3oNYdbiWeQ8k8OTa57kcPXh1q+VMcaYgFps3nHTMGwGrsDpvvkx\nMFtVi3zKDAHGADcA5erm3hFngOe/ARNV9ZSbr2S5qs73+w1tqEO91rOidAXeQi/Ltizjq+O+iifH\nw1fGfoWkLkkRW2ljjGnvotW805Y0DBXud73cQTx64Rw4mq+MdOHLY7/MolmLKH2glC+lfYmHVzxM\n2u/SeOhvD7HtyLZw1s0YY4yfYEE/UBqGkc2UbURVjwD/jTPgxz7gqKr+JdSKDeg5gHs/fy8f/8vH\nLPv6Mo7XHOeiuReROy+XBesXcLzG0mwbY0y4ggX9Vt9VdTNq/gfO0H4jgBQRub01y5o6bCq/nflb\n9jy4h/un38/ijYsZ/dvR3PPGPXy450O7+WuMMSEK1k+/LWkYpuGMg3kYQERexRlIYZF/wUcfffTM\n+9zc3Gb783ZL6saNk27kxkk3srdiLwvWL2DO0jkkd0nGk+NhztQ5DEsZFmL1jDGm/Vi5ciUrV65s\n83KC3cjtinMj98s4TTQf4Xcj16fso0Clz43c83AC/OdxsmzOAz5S1af95tO2nKmrKqt3rcZb6GVp\n0VJy03Lx5Hi4MuNKkpOSW71cY4xJZK29kRvKyFlXcnbkrLmq+vOW0jDg5ByfpKpVIvJ94C73+3XA\nN90bwr7Lb1PQ91V5qpKXNr6Et9DL9vLtzJk6B0+Oh6zBWRFZvjHGJIqoBf1oi2TQ91VcVkx+QT4L\nPllAev90PDkebpl8C3279434bxljTKxZ0G9GbX0tb219C2+hlxWlK7gh6wY8OR4uSb0EkbC3lzHG\nJAQL+iE4UHWAhZ8sxFvopaauhrzsPO467y5G9g2pF6oxxiQMC/phUFU+2vsR3gIvL296mQtHXYgn\nx8O1mdfSvWvATBHGGJNQonkjdyZnb+T+UVV/6Tc9C8gHcoAf+/TemYDzBG+DscDDqvqk3/wxD/q+\nqk9Xs2TTEvIL89lwcAO3T7kdT46HqcOmxq1OxhgTTFSCflty7/gtp4s7/3RV3e03La5B39e2I9uY\nVziPeevnMaz3MDw5HmafO5sBPQfEu2rGGNNIIube8XUFsM0/4CeacQPH8dPLf8qOB3bws8t/xns7\n3yP9d+l8fcnX+cv2v1CvTcZ1N8aYdiXYE7mBcu9c0IrfuY12ND5uUpckZmTMYEbGDA5XH+b5Dc/z\nvXe/R/mJcu7Ovpu7s+8mrX9avKtpjDFhCxb029zu4g6ofi3QJBd/g1DTMMTDoF6DuP+C+7n/gvsp\n2F9AfmE+0/4wjezh2XhyPHwt62v0TO4Z72oaYzq4WKVhuBB4VFVnup9/BNT738x1pz0CVPm36YvI\n9cC9DcsIMJ9+7WtKRgZkZMC4cc7fUaMgKUFT6J+sPclrxa/hLfSydt9abp18K54cD+efc771/TfG\nxES0buS2OveOz/cvAm/5D57iM11fekkpKeHMa9s2KCuD9PSzBwHfg0JaGiQnSFqdXcd2Mb9wPvmF\n+fTp3gdPtofbp97O4F6D4101Y0wHlqi5d3oDO4F0Va1sZvkBe+9UV8P27WcPAr4HhX37nCsB/6uD\njAwYOxZ6xGGM9Xqt570d7+Et9PLG5je4YuwVeHI8fHXcV+naJVgrmjHGhKdTPZxVUwM7dtDk6qCk\nBHbuhCFDml4dNPzt0yc66+Hr2MljLN64GG+Bl90Vu7nrvLvIy85j/KDx0f9xY0yn0KmCfktqa2H3\n7qZXB9u2Oa++fZs2GTUcEAYOjFg1zth4cCPeAi8LNyxkwqAJeHI83DzpZnp36x35HzPGdBoW9ENQ\nXw/79ze9Omh4de0auMkoIwOGDoW23KOtqath2ZZleAu9rN61mpsm3kReTh4XjbrIbv4aY8KWcGkY\n3Gn9gT8Ck3G6f3pU9UO/+RPiiVxV5+ZxoCajkhI4dSrwTeWMDBg5EroEe8zNx77KfTy3/jm8hV4E\nwZPj4c7z7mR4yvDoraAxpkNJyDQMIjIfeE9VvW5PoN6qeszvNxIi6Adz9GjgJqOSEigvd24gBzoo\njBnjXEEEoqp8sOcDvAVelhQt4ZLUS/hGzje4avxVNuqXMaZF0Qr6FwGP+PTT/yGAqv4iQNlG/fRF\npB9QoKpjg1S8XQT9llRVNd/T6LPPIDU1cJNRejp0d5N6VtVU8fLGl/EWetl6eCtzps4hLyePSUMm\nxXfljDEJqbVBP5ppGNKBQyKSD5wH/BN4QFWrw61koktJgalTnZe/U6egtLTx1cHbbzvvd+2C4cMb\nDgIpZGTk8Z1xeXTN3MLfK/K5YsEVpPZLxZPj4dbJt9KvR7/Yr5wxpkOJZhqGrsDngPtU9WMReQL4\nIfAT/4KJnIahrbp3h6ws5+WvttYJ/L5XBqtWwbZtmWzf/nP6D/wplZ9/m8e35PNA7+/z+b7Xcfsk\nDzdPv5SBA8K4iWCMafcSPg2D+9DWB6qa7n7+IvBDVb3Gb75237wTDfX1sHfv2auDT0oO8V75Irb0\nnsspraZHUR4TTt7N5FGjmjQbDR7ctp5GxpjEF63mnbXAeBFJw0nDcCswu7k6+H5Q1c9EZLeIZKrq\nFpybwRvDrWBn1aULjB7tvL70JYAhwH+g+gBr9/2Tp9/3snTredR1nc7JKg/Ff76O0q3dKSlxriAC\n9TLKyIBzzgmvp5ExpmOJdhqG83C6bHYDtgF57bX3TiI6cfoES4uX4i3wsv7AemafOxtPjofUbtnN\n9jSqqHB6GgV6OC01NXGT3BljGrOHszq50vJS5q93Er8N6jmIb+R8g9lTZjOwZ+PHjCsrzz6d7H9Q\nOHjQ6WIaqKdRWhp06xafdTPGNGVB3wBO4re/lf4Nb4GX5VuXc+X4K/Fke7g8/XKSurR8Gn/ixNme\nRv4HhT17YMSIwM1GY8dCr14xWkFjDGBB3wRQfqKcFz59AW+Bl0PVh7j7PGfUr/QB6WEv6/RpJ5ld\noCaj0lLn5nFzTyz37RuFlTOmk0vUNAw7gAqgDjitqtMDLN+Cfgys/2w9+YX5LNqwiKnDpuLJ9jBr\n4qyIjPpVV+dcCTR3H6F378BNRhkZTpI762lkTPgSNQ1DKXC+qh5p4Tcs6MfQqdpTvLHlDbwFXtbs\nXcMtk27Bk+Nh2ohpUUn8puo8lRyoyaikxCnTXE+j4cPtgGBMcxIuDYP7XSkwTVUPt/AbFvTjZE/F\nHhasX4C3wEvP5J54sj3cMfUOhvQeEpPfV4UjR5pPcnf8ePNNRok8nKYxsRCtoH8TMENV/8X9fAdw\ngareH6BsoKC/HTiG07zzjKo+G2A+C/pxpqqs2rUKb4GX1za/xuXpl5OXncfMjJlxHfWroqL5JqOG\n4TQDNRuNGZM4w2kaEy3RejirrdH4YlXd7zYBvSsixaq6yr9QR07D0B6ICJeOuZRLx1xKxakKXtr4\nEo+vepx73rjHGfUrJ4/MQZkxr1ffvpCT47z8+Q+nuXEjvPZa4g6naUxbJXwahlCn25l+4io6VER+\nYT4L1i9g/KDxeLI93Dz5ZlK6pcS7ai3yH07T92oh0HCaDQeGWA2naUwkRKt5pyvOjdwv46Rh+Ai/\nG7k+ZR8FKn1y7/QCklS10h0g/R3gMVV9x28+C/oJ7nTdad4qeQtvgZf3dr7HrKxZeHI8fGH0F9rd\nqF91dc5wmv43lH2H0/Q/CCQlOWMitPZvW+ZNSrKb2SawaHbZbFUaBmAo8Kq7mK7AIlX9eYDlW9Bv\nRz6r+oyFnyxkbsFc6rUeT7Yz6tc5fc6Jd9XazHc4zYaDQHW1k8uottY5YMT6b12dkyuprQeeeB+4\nov23Mx4Y7eEsE1Oqypq9a/AWeHll0ytcnHoxnmwPV2deTbcky9cQKarOwSiaB5d4HdBifWCM94Ep\n0gfhyZMt6Js4OV5znCVFS/AWeCkqK+KOKXeQl5PHuUPPjXfVTCfQ0oEx3gekaP4tKrKgbxJAyZES\n5hXOY17hPEb2HYkn28Nt595mo34ZE2HWvGMSSl19He9ufxdvgZd3tr3DtROuxZPt4bK0y+giltDf\nmLZKyNw77vQknMFY9qjqtQGWb0G/gyurLuP5Dc8zt2AulacqycvO467su0jtlxrvqhnTbiVk7h13\n+oPA+UAfVb0uwG9Y0O8kVJWCzwrwFnh58dMXOX/E+XiyPVyfdT09utoTU8aEo7VBP9h19nSgRFV3\nqOpp4EXget8CqnpIVdcCpwNUahRwFc7oWZ2wU5XxJSJ87pzP8dRVT7HnwT3kZecxt2Auo34zivuX\n30/B/oJ4V9GYDi9Y0B8J7Pb5vMf9LlS/Bb6H03/fmDN6dO3Bbefexjtz3uGf9/yTIb2HMOulWeQ8\nk8Pv1/yew9XN5ugzxrRB1HLviMg1wEFVLRCR3JbKWu6dzm1M/zH85LKf8NClD7Fyx0q8BV4eXvEw\nMzJm4Mn2cMXYK4KO+mVMR5fwuXdE5HFgDlAL9MB5YneJqt7pN5+16Zsmjp48youfvoi3wMv+qv1n\nRv0aN3BcvKtmTEJIuNw7ftMuA/7Teu+Y1thwYAP5hfks/GQhk4dOxpPt4cZJN9Ir2QbmNZ1XwuXe\nUdUqn2VcBnzXeu+Ytqipq+HNLW/iLfDy/u73uXnSzXhyPEwfOb3dJX4zpq3s4SzTqeyr3Hdm1K/k\npOQzo34NSxkW76oZExMW9E2npKr8Y/c/8BZ4WVq8lNy0XDzZHq4cf2VcR/0yJtos6JtOr/JUJS9v\nehlvgZdt5du4c+qd5OXkkTU4K95VMybiovVwFiIyU0SKRWSriPwgwPQsEflARE6KyHd9vu8hImtE\npFBENolIk1z6xkRSn+598OR4WO1Zzcq7ViIiXD7/ci72XszcdU4KCGM6u6imYRCRXqpa7fYCWo3T\ng2e132/Ymb6Jmtr6Wv5c8me8BV5W7FjBDVk34Mn28MXUL9rNX9OuJWQaBlWtdt92w+n9cyTcChrT\nFl27dOWazGt49dZX2XzfZqYMncK3l32bzKcy+fmqn7O3Ym+8q2hMTEU1DYOIdBGRQuAAsEJVN4Vf\nRWMiY2jvoTx40YN8eu+nLJq1iJ3HdjLl/0/h6uevZsmmJdTU1cS7isZEXdTSMACoaj2QLSL9gLdF\nJFdVV/qXszQMJpZEhOkjpzN95HR+M+M3vFr0Kk9//DT3LruX26fcjifHw5RhU+JdTWMaSfg0DAGm\nPwycUNVf+31vbfomIWwv335m1K9hKcPIy87jktRLyByUSfeu3eNdPWMaSbg0DCIyGKhV1aMi0hN4\nG3hMVf/qN58FfZNQ6urr+GvpX1mwfgHr9q+j9GgpI/uMZOKQiWQNymLikIlMHDyRrMFZDOg5IN7V\nNZ1UwqVhAMYC83DuG3QBnlPVXwVYvgV9k9BO151me/l2isqKKC4rPvv3UBG9knuRNTjrzEFg4hDn\n7+i+o613kIkqezjLmBhTVfZV7mt8IHD/Hjt5jAmDJ5w9GLh/xw8aT7ekbvGuuukALOgbk0COnTzG\n5sObKTrU+GCw4+gOUvulNmoqajgo9OvRL97VNu2IBX1j2oGauhq2HdnW6Mqg6FARmw9vpk+3PgGb\nikb2GWlNRaaJqAZ9EZnJ2Xb9P/r33hGRLCAfyAF+7HMzdzSwABiK0/3zD6r6pN+8FvRNp6eq7KnY\nE7CpqKqmqvHBwP2bMTCD5KTkeFfdxEk0b+S2OhWDe5N3uKoWikgK8E/gBr95Legb04LyE+UBm4p2\nHdtFWv+0Jk1FWYOz6Nu9b7yrbaIsmkH/IuARn776PwRQ1V8EKBusr/6fgN/7dtu0oG9M65yqPUXJ\nkZImVwabyzbTr0e/RlcGDQeEc1LOsaaiDqK1QT+UhOOBUjFcEO4PiUgaTvPPmnDnNcY01b1rdyYP\nnczkoZMbfV+v9eyp2EPRoSKKyorYcHADL216ieKyYk7WngzYVDRu4Dgbf6CTCOVfuc2n4W7TzivA\nA77DKDawNAzGRE4X6UJqv1RS+6UyI2NGo2lHThw584xBcVkxz657luKyYvZW7iW9f3rApqKUbilx\nWhPjKyZpGKDtqRhEJBl4E3hLVZ8IMI817xgTZydrT7L18NYmTUVbDm9hYM+BTa4MJg6ZyLDew6yp\nKI6i2abfllQMAswHDqvqd5pZvgV9YxJUvdaz8+jOgL2KautrAzYVpQ9It6aiGIh2l83WpmLIBv4O\nfMLZZqIfqeqffZZtQd+YdqisuqxRU1HDwWB/1X7GDRjXpKlowqAJ9O7WO97V7jDs4SxjTEKoPl0d\nsKlo6+GtDOk9JGBT0ZBeQ6ypKEwW9I0xCa2uvo6dx3Y2ujJoeCIZCJjFNK1/GkldkuJc88RkQd8Y\n0y6pKoeqDwVsKjp4/CAZAzMCNhX1TO4Z76rHVUKmYXCneYGrgYOq2mQ4Igv6xpjmHK85zpbDW5o0\nFZUcKWF4yvCATUWDew2Od7VjIiHTMLjTLgGqgAUW9I0xkVBbX8uOozvOPIDmm7yua5euAbOYjuk/\nhi4SbFjw9iOh0zC4T+O+YUHfGBNNqsqB4wcCNhWVVZeROSizyQEhc1AmPbr2iHfVw5bwaRiMMSba\nRIThKcMZnjKc3LTcRtOqaqrYXLb5zEFg8cbFFJcVs718OyP6jAjYVDSw58D4rEgUxSQNgzHGxFtK\ntxTOH3E+5484v9H3p+tOU3q09MyVwapdq/jDuj9QXFZM96TuAZuKRvcb3W6bikIJ+nuB0T6fR+Oc\n7UeM5d4xxsRLclIymYMyyRyUyfVcf+Z7VWV/1f5GTUVvbnmT4rJiyk+WM2HQhCZXBuMHjqd71+5R\nqWcsc++0Og2Dz/dpWJu+MaaDqDhV0aipqOFvaXkpo/uNDthU1L9H/4jWISHTMKhqlYi8AFwGDAIO\nAj9R1XyfZVvQN8Z0CDV1NWwv396kV1FxWTG9k3sHbCoa1XdUq55GtoezjDEmQakqeyv3BuxVVFlT\nGbCpKGNgBt2SujW7TAv6xhjTDh09eTRgU9HOozsZ039MwEym/Xr0s6BvjDEdyanaU2wr39bkyqC4\nrJi+3fuy/z/3W9A3xpiOrmE4zDH9x7Qq6AftaCoiM0WkWES2isgPAkzPEpEPROSkiHw3nHlN5EWi\nS5c5y7Zn5Ni2jIyG4TBbPX9LE928O08BM3EGRZktIhP9ih0G7gd+3Yp5TYTZf6zIsu0ZObYtE0Ow\nM/3pQImq7lDV08CL4PP0AqCqh1R1LXA63HmNMcbEVrCgHyjvzsgQl92WeY0xxkRBsDQMbbnDGvK8\nNkxaZD322GPxrkKHYtszcmxbxl+woN+WvDshzduau8/GGGNaJ1jzzlpgvIikiUg34Fbg9WbK+gfv\ncOY1xhgTAy2e6atqrYjcB7zN2bw7RS3l3RGRBzibd6fJvNFcGWOMMS2L+8NZxhhjYidmowCE8qCW\niDzpTl8vIjmxqlt7FMJDc7kickxECtzXQ/GoZ3sgIl4ROSAiG1ooY/tmCIJtS9svwyMio0VkhYhs\nFJFPReTfmykX+v6pqlF/4TTvlABpQDJQCEz0K3MVsNx9fwHwYSzq1h5fIW7PXOD1eNe1PbyAS4Ac\nYEMz023fjNy2tP0yvO05HMh236fgjG3SptgZqzP9UB7Uug6YD6Cqa4D+IjIsRvVrb0J98M16RoVA\nVVcB5S0UsX0zRCFsS7D9MmSq+pmqFrrvq4AiYIRfsbD2z1gF/VAe1ApUZlSU69VehbI9FfiCe7m3\nXEQmxax2HY/tm5Fj+2UruSMQ5gBr/CaFtX+GMkZuJIR6t9j/DMDuMgcWynZZB4xW1Wp35LM/AZnR\nrVaHZvvYucN9AAABG0lEQVRmZNh+2QoikgK8AjzgnvE3KeL3udn9M1Zn+qE8qOVfZpT7nWkq6PZU\n1UpVrXbfvwUki8jA2FWxQ7F9M0JsvwyfiCQDS4CFqvqnAEXC2j9jFfRDeVDrdeBOABG5EDiqqgdi\nVL/2Juj2FJFh4ua3EJHpON1zj8S+qh2C7ZsRYvtleNxtNRfYpKpPNFMsrP0zJs07GsJDXqq6XESu\nEpES4DiQF4u6tUehbE/gJuBeEakFqoHb4lbhBCciLwCXAYNFZDfwCE6vKNs3wxRsW2L7ZbguBu4A\nPhGRAve7/wJSoXX7pz2cZYwxnUjMHs4yxhgTfxb0jTGmE7Ggb4wxnYgFfWOM6UQs6BtjTCdiQd8Y\nYzoRC/rGGNOJ/C/KqrAeLFaf7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaa12d70c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(test_err_m01)\n",
    "ax.plot(train_err_m01)\n",
    "ax.set_title('Test MSE/Training MSE   m = 0.01')\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.9, 0.5))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(test_err_m2,label = 'Test error')\n",
    "ax1.plot(train_err_m2,label = 'Training error')\n",
    "ax1.legend(loc='center right', bbox_to_anchor=(1.4, 0.5))\n",
    "ax1.set_title('Test MSE/Training MSE   m = 2')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(test_err_m20)\n",
    "ax2.plot(train_err_m20)\n",
    "ax2.legend(loc='center right', bbox_to_anchor=(1.3, 0.5))\n",
    "ax2.set_title('Test MSE/Training MSE    m = 20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\vspace{5mm}\n",
    "\n",
    "It's clear from the figure that when increase the complexity of the model the training error tend to zero. It's more interesting see that the test error that have an U-shape (a really smooth U-shape in this case). Infact in general the expected test MSE can be always decomposed into sum of three fundamental quantities:\n",
    "\n",
    "1) the variance of the estimated function $\\hat{f}$ \n",
    "2) the squared bias of $\\hat{f}$ \n",
    "3) the irriducible variance $\\varepsilon$ \n",
    "\\vspace{5mm}\n",
    "\n",
    "the variance refers to the amount by which $\\hat{f}$ change if we change also the data and the bias is the amount of error that you obtain when your model is too simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
